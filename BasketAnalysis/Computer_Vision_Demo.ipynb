{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56181ac5-54f7-4202-8ea1-93fd2ab312bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Demo of Azure Computer Vision applied to Business Intelligence\n",
    "# Basket Analysis\n",
    "\n",
    "\n",
    "<b>Role:</b> Data Scientist, Data Engineer, Machine Learning Engineer\n",
    "\n",
    "<b>Topic:</b> A generalized schema for basket analysis of data trapped in photos, using Azure Computer Vision.\n",
    "\n",
    "<b>Purpose:</b> Demonstrate a way that the immense interest in A.I. (circa Feb 2023) can be used to unlock a tremendous amount of valuable B.I. data locked away in unstructured photos and images.\n",
    "\n",
    "<b>Background:</b> In late November 2022, the phenomenon of ChatGPT was born. For the first time, a sufficiently impressive, performant, and most of all, easy-to-use A.I. was available to a wide audience. Basically, anyone with an Internet connection. \n",
    "\n",
    "The importance of this phenomenon is that A.I. looks like it's at the \"hockey stick curve\". A.I. has been permeating our lives for the past decade rather quietly. That is, through Siri, Alexa, armies of bots, etc.\n",
    "\n",
    "While this demo isn't about ChatGPT, it is about the equally impressive Microsoft A.I. offerings, collectively called Azure Cognitive Services. \n",
    "\n",
    "<b>Copyright (c) 2021 - 2023 Kyvos Insights</b>\n",
    "\n",
    "Permission is hereby granted, free of charge, to customers of Kyvos Insights obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "\n",
    "<b>Authored by:</b> Eugene Asahara<br>\n",
    "<b>Date Created: </b> February 12, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b702cab-0552-4edf-ad29-ae0d0e64d525",
   "metadata": {},
   "source": [
    "# Computer Vision and Business Intelligence\n",
    "\n",
    "<b>Azure <i>Computer</i> Vision</b> is a set of pre-trained models capable of recognizing objects and text in images and video. This consists of widespread and common topics such as food, people in general, animals, famous locations, famous people.\n",
    "\n",
    "<b>Azure <i>Custom</i> Vision</b> is a platform for training custom domain models, beyond the common objects training in Computer Vision. For example, an enterprise may be in the farming business. A model could be trained to recognize things related to farming, but not the general public. That might include various machinery, types of feed, types of fertilizers, what healthy corn looks like, various fungus. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5976b5a3-85f9-4d7b-800c-40599a96fdca",
   "metadata": {},
   "source": [
    "# What Fires Together Wires Together\n",
    "\n",
    "A fundamentel of logical thinking is to correlate things/events that appear together.\n",
    "\n",
    "<img src=\".\\images\\basket_analysis.jpg\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214c5e20-b2c0-4e91-9873-660a66e7f5af",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "\n",
    "<img src=\".\\images\\azure_computer_vision_architecture.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeab9a3-a7ae-4177-be8f-54b4ad2be353",
   "metadata": {},
   "source": [
    "# Set up Azure Computer Vision\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae11604a-7695-473b-a474-3eacb06aa9ce",
   "metadata": {},
   "source": [
    "# Set up .env file\n",
    "\n",
    "\n",
    "<img src=\".\\images\\env_file_computer_vision.jpg\"/>\n",
    "\n",
    "<b>COMPUTER_VISION_KEY=\"Enter Azure Computer Vision Key here\"</b>\n",
    "\n",
    "<b>COMPUTER_VISION_ENDPOINT=\"Enter Azure Computer Vision Endpoint here.\"</b>\n",
    "\n",
    "<b>COMPUTER_VISION_IMAGE_PATH=\"c:/temp/computer_vision/\"</b>\n",
    "\n",
    "<b>SAVE_FILENAME = \"C:\\\\temp\\\\computer_vision.json\"</b>\n",
    "\n",
    "Location to save the raw json created when processing the picture. This is the primary data source. \n",
    "\n",
    "This is the input for the basket analysis.\n",
    "\n",
    "<b>FREQUENT_ITEM_SETS=\"C:\\\\temp\\\\computer_vision.csv\"</b>\n",
    "\n",
    "Itemsets are objects found together in each photo. This is created through a function in the apriori package.\n",
    "\n",
    "This is the basket analysis data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cfe6d4-55d0-4331-af3d-1bc120a06464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Functionality to retrieve Kyvos cube metadata - dimensions, attributes, members.\n",
    "from kypy.Metadata import AzureComputerVisionLib as az"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9594d33-e426-4049-81a3-99102e09395f",
   "metadata": {},
   "source": [
    "# Basket Analysis Demo\n",
    "\n",
    "For this demo, we analyze a very small set of \"baskets\" of fruits. Each photo is a basket.\n",
    "\n",
    "<img src=\".\\images\\basket_analysis_demo.jpg\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a3ea1a-4dc3-4c43-8b17-1c4534d6db87",
   "metadata": {},
   "source": [
    "# Set up Computer Vision demo parameters\n",
    "\n",
    "### Recognized Tags\n",
    "\n",
    "Azure Computer Vision will return very many tags from each photo. We probably won't be interested\n",
    "in all of them, so we can specify the tags we are interested in. \n",
    "\n",
    "For the sake of simplicity, we will restrict it to a small set of fruit:\n",
    "\n",
    "<b>recognized_tags</b> = [\"mango\",\"grapefruit\",\"grape\",\"oranges\",\"apple\", \"pear\", \"clementine\",\"banana\"]\n",
    "\n",
    "In reality, we would be interested in many more things than this.\n",
    "\n",
    "### Minimum Support\n",
    "\n",
    "If a group of items appears in more than one basket, it is an interesting data point. It's especially interesting\n",
    "if it appears in many baskets. <b>min_support</b> is a minimum percentage of baskets that a group should belong to in order\n",
    "to be saved as a group. \n",
    "\n",
    "In reality, the min_support might be very small. For example, we might be President Biden and VP Kamala Harris in many photos, but there's nothing\n",
    "very newsworthy about that. But seeing a particular KGB spy and a particular CIA spy together in two or three photos out of thousands is intersting. In a\n",
    "real enterprise scenario, we are able to store a larger volume of groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f462c16-4795-4ef1-81c6-55cfda026e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up computer vision parameters.\n",
    "recognized_tags = [\"mango\",\"grapefruit\",\"grape\",\"oranges\",\"apple\", \"pear\", \"clementine\",\"banana\"]\n",
    "min_support = 0.2 # 20% of images should have the group.\n",
    "max_len = 5 # Most number of items in a group.\n",
    "min_confidence = 0.6 # Minimum confidence of an item recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500b4fd5-7438-49f6-b217-35d01e71f64b",
   "metadata": {},
   "source": [
    "# Create class that handles the interface between Azure Computer Vision and Kyvos OLAP Cubes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857721ed-e030-4e9d-b0ac-806318a5b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ObjectGroups object that encapsulates the functionality that involves Azure Computer Vision.\n",
    "cvo = az.ObjectGroups() # cvo is \"Computer Vision Object\".\n",
    "# CreateGroup executes against Azure Computer vision. It presents each of the photos in the\n",
    "# folder specified in the .env file with the COMPUTER_VISION_IMAGE_PATH entry.\n",
    "cvo.CreateGroup(\n",
    "    min_support=min_support, \n",
    "    recognized_tags=recognized_tags,\n",
    "    max_len=max_len,\n",
    "    min_confidence=min_confidence\n",
    ")\n",
    "print(cvo.frequent_itemsets.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f5e718-36c8-46be-a43b-34fc8ab39384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the \"raw\" results (json) from Azure Computer Vision.\n",
    "# Note that all the tags (not just the ones we requested in \"recognized tags\").\n",
    "print(json.dumps(cvo.tags,default=str, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df7c414-8c21-4a64-b70e-d354e22a1fe4",
   "metadata": {},
   "source": [
    "# Data files for the OLAP cube Basket Analysis Schema.\n",
    "\n",
    "The following few cells show how to retrieve data for the tables in the basket analysis schema below:\n",
    "\n",
    "<img src=\".\\images\\computer_vision_schema.jpg\"/>\n",
    "\n",
    "Note that the fact tables are association/bridge tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a0de83-4812-4755-a45a-49509427aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the items dimension. These are recognized tags from among all the images processed.\n",
    "print(cvo.item_dimension.head(100))\n",
    "print(cvo.group_dimension.head(100))\n",
    "print(cvo.basket_dimension.head(100))\n",
    "print(cvo.basket_group_fact.head(100))\n",
    "\n",
    "# This is a fact table of all recognized items and groups they are in.\n",
    "print(cvo.item_group_fact.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf3d35e-ce0a-4a87-9349-174cb9b3bbe5",
   "metadata": {},
   "source": [
    "# A Few Sample Query functions.\n",
    "\n",
    "\n",
    "Reports that could be gleaned through the schema:\n",
    "\n",
    "<ul>\n",
    "    <li>Which items appear together often?</li>\n",
    "    <li>How many times did a group of items appear together?</li>\n",
    "    <li>What groups does an item appear with?</li>\n",
    "</ul>\n",
    "\n",
    "## List baskets that contain apple OR mango.\n",
    "\n",
    "Note that the create_date offers the order in of the images. So we know that pictures with apple or mango\n",
    "appeared at these times. \n",
    "\n",
    "If we were recognizing people, we would have a chronology of when and where a person appeared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e012e-e5de-44d3-9554-6e4272e81a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sample_queries():\n",
    "    print(\"Baskets with apple OR mango.\")\n",
    "    print(cvo.get_baskets([\"apple\",\"mango\"]).head(100))\n",
    "    \n",
    "    print(\"List baskets that include apple AND mango.\")\n",
    "    print(cvo.get_baskets([\"apple\",\"mango\"], item_in=False))\n",
    "\n",
    "    print(\"Display the confidence of the apple recognized in the file is indeed an apple.\")\n",
    "    print(cvo.get_tag_confidence( \"apple\",\"apples_orange_grape.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea2efd-c84d-4cb6-8fe7-af6cc270ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sample_queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc77533-806b-4c09-b062-28462a295b9c",
   "metadata": {},
   "source": [
    "# Fact table of all items in every basket. \n",
    "\n",
    "This is a association/bridge table.\n",
    "\n",
    "It's a virtual table since it could be very long if there are a large number of baskets. For example, consider something like\n",
    "Web searches. Google has billions of them each day. Each of those searches consist of a number of key words. So there are several\n",
    "times for keyword-search rows than just search rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ce1a8-36cc-4729-8dbb-3256bbb52d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvo.item_basket_fact.head(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c70437-5d53-4aaa-b1eb-3499c9fb10de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All items - not just the ones we chose to recognize.\n",
    "# basket_count is the number of distinct baskets containing the item.\n",
    "print(cvo.all_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4396981a-00ba-413d-9a2d-82566db014cf",
   "metadata": {},
   "source": [
    "# Save Data.\n",
    "\n",
    "Save the data files to the directory specified in the COMPUTER_VISION_SAVE_DATA_PATH .env key\n",
    "\n",
    "They are the files we viewed in the prior few cells:\n",
    "<ul>\n",
    "    <li>basket_dimension.csv</li>\n",
    "    <li>basket_group_fact.csv</li>\n",
    "    <li>computer_vision.json</li>\n",
    "    <li>computer_vision_frequent_itemsets.csv</li>\n",
    "    <li>group_dimension.csv</li>\n",
    "    <li>item_basket_fact.csv</li>\n",
    "    <li>item_dimension.csv</li>\n",
    "    <li>item_group_fact.csv</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691c612e-70d1-4b30-b944-b06736b5fc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvo.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d19be1a-33b8-4f4c-a587-20d55428e1fc",
   "metadata": {},
   "source": [
    "# Read Existing Basket Analysis Data\n",
    "\n",
    "We will re-read the primary json file we just saved (computer_vision.json).\n",
    "\n",
    "Then we'll run those same queries to show that the data has been reloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21f7d4-07ac-495e-bd7a-a954302bac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvo.read(min_support=min_support, max_len=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055073a7-ef8d-4ec5-ba78-e5e0da10cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sample_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0930143-b175-4b4a-adde-71e25200b184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa06ad-90d3-4cb0-a58e-12771d47e51b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
